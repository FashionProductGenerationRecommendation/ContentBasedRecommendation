-- Big Data Commands

-- Cluster Codes
ssh -i /home/rutvij/.ssh/id_rsa rmehta@13.58.184.203

Copy files to cluster using scp
scp a3_p1_112689056.py rmehta@13.58.184.203:/home/rmehta/part1
scp Software_5.json.gz rmehta@13.58.184.203:/home/rmehta/part1

Copy files from cluster to HDFS in cluster
hadoop fs -copyFromLocal /home/rmehta/tryFirst/alko170.txt /user/rmehta/alko170.txt
hadoop fs -copyFromLocal /home/rmehta/tryFirst/covid19_full_data.csv /user/rmehta/covid19_full_data.csv
hadoop fs -copyFromLocal /home/rmehta/tryFirst/populations.csv /user/rmehta/populations.csv

spark-submit SparkWordCount.py /user/rmehta/alko170.txt

spark-submit SparkCovid19_1.py /user/rmehta/covid19_full_data.csv true /home/rmehta/tryFirst/output_1/
spark-submit SparkCovid19_2.py /user/rmehta/covid19_full_data.csv 2020-01-01 2020-03-31 /home/rmehta/tryFirst/output_2/
spark-submit SparkCovid19_3.py /user/rmehta/covid19_full_data.csv /home/rmehta/tryFirst/output_3/


-- Commands

-- Task 2
spark-submit a3_p2_mehta_112689056.py hdfs:/Software_5.json.gz ["B00EZPXYP4", "B00CTTEKJW"]

spark-submit a3_p2_mehta_112689056.py Software_5.json.gz ["B00EZPXYP4", "B00CTTEKJW"]
spark-submit working22.py Software_5.json.gz ["B00EZPXYP4", "B00CTTEKJW"]
spark-submit working1_try.py Software_5.json.gz ["B00EZPXYP4","B00CTTEKJW"]

spark-submit a3_p2_mehta_112689056.py hdfs:/Books_5.json.gz ["0001713353", "0002005263"]


spark-submit working22.py gs://assignment3rutvijbda/Software_5.json.gz "["B00EZPXYP4","B00CTTEKJW"]"
spark-submit working22.py gs://assignment3rutvijbda/Books_5.json.gz "["0001713353","0002005263"]"


spark-submit working22.py hdfs:/data/Software_5.json.gz "["B00EZPXYP4", "B00CTTEKJW"]"


spark-submit working22.py gs://assignment3rutvijbda/Books_5.json "["0001713353","0002005263"]"


spark-submit working20.py gs://assignment3rutvijbda/Books_5.json "["0008118922","1469216051"]"



Task 1:
spark-submit working11.py gs://assignment3rutvijbda/Software_5.json.gz


docker run -it -v "$(pwd)":/home sequenceiq/hadoop-docker:2.7.1 /etc/bootstrap.sh -bash

-- setting path variables
export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8
export PATH=$PATH:/usr/local/hadoop/bin/

-- substitute of put
hadoop fs -copyFromLocal /home/TODB_HW4/alko170.txt /user/root/alko170.txt
hadoop fs -copyFromLocal /home/TODB_HW4/covid19_full_data.csv /user/root/covid19_full_data.csv
hadoop fs -copyFromLocal /home/TODB_HW4/populations.csv /user/root/populations.csv

-- hadoop commands to run WordCount.java
javac -cp `hadoop classpath` WordCount.java -d build -Xlint
jar -cvf WordCount.jar -C build/ .
ls -lt
hadoop jar WordCount.jar WordCount /user/root/alko170.txt /user/root/wordcountoutput
hdfs dfs -cat /user/root/wordcountoutput/*
hdfs dfs -rm -r /user/root/wordcountoutput


hdfs dfs -cat /user/root/covid19_1_output/*
hdfs dfs -rm -r /user/root/covid19_1_output


-- Task 1
javac -cp `hadoop classpath` Covid19_1.java -d build -Xlint
jar -cvf Covid19_1.jar -C build/ .
hadoop jar Covid19_1.jar Covid19_1 /user/root/covid19_full_data.csv True /user/root/covid19_1_output
hdfs dfs -cat /user/root/covid19_1_output/*
hdfs dfs -rm -r /user/root/covid19_1_output

-- Task 2
javac -cp `hadoop classpath` Covid19_2.java -d build -Xlint
jar -cvf Covid19_2.jar -C build/ .
hadoop jar Covid19_2.jar Covid19_2 /user/root/covid19_full_data.csv 2020-04-02 2020-04-03 /user/root/covid19_2_output
hdfs dfs -cat /user/root/covid19_2_output/*
hdfs dfs -rm -r /user/root/covid19_2_output

-- Task 3
CD TO HOME
hadoop fs -copyFromLocal /home/TODB_HW4/populations.csv /user/root/populations.csv
javac -cp `hadoop classpath` Covid19_3.java -d build -Xlint
jar -cvf Covid19_3.jar -C build/ .
hadoop jar Covid19_3.jar Covid19_3 /user/root/covid19_full_data.csv /user/root/covid19_3_output
hdfs dfs -cat /user/root/covid19_3_output/*
hdfs dfs -rm -r /user/root/covid19_3_output


-- Cluster Codes
ssh -i /home/rutvij/.ssh/id_rsa rmehta@13.58.184.203

Copy files to cluster using scp
scp /home/rutvij/Desktop/TODB_HW4/SparkCovid19_1.py rmehta@13.58.184.203:/home/rmehta/tryFirst

Copy files from cluster to HDFS in cluster
hadoop fs -copyFromLocal /home/rmehta/tryFirst/alko170.txt /user/rmehta/alko170.txt
hadoop fs -copyFromLocal /home/rmehta/tryFirst/covid19_full_data.csv /user/rmehta/covid19_full_data.csv
hadoop fs -copyFromLocal /home/rmehta/tryFirst/populations.csv /user/rmehta/populations.csv

spark-submit SparkWordCount.py /user/rmehta/alko170.txt

spark-submit SparkCovid19_1.py /user/rmehta/covid19_full_data.csv true /home/rmehta/tryFirst/output_1/
spark-submit SparkCovid19_2.py /user/rmehta/covid19_full_data.csv 2020-01-01 2020-03-31 /home/rmehta/tryFirst/output_2/
spark-submit SparkCovid19_3.py /user/rmehta/covid19_full_data.csv /home/rmehta/tryFirst/output_3/


